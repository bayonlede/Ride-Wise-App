








# from google.colab import drive
# drive.mount('/content/drive')





import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings # Ignore all warnings
warnings.filterwarnings("ignore")





master_df  = pd.read_csv('../data/processed_data/trip_riders_drivers_eda_df.csv')
rfm_df = pd.read_csv('../data/processed_data/rfms_table.csv')

print('dataframes ingested successfully as expected')
print(f'The master_df shape is:')
print(master_df.shape)
print(f'The rfm_df shape is:')
print(rfm_df.shape)





master_df.head(2)


master_df.info()  # master dataframe info








rfm_df.head(2)  # RFM dataframe





rfm_df.drop(columns=['r', 'f','m','s','rfm_concat','rfm_score','weighted_segmentation'], inplace=True)
rfm_df.head()





master_rfm_df = pd.merge(master_df,rfm_df,on='user_id')


master_rfm_df.head(2)








master_rfm_df['last_active'] = pd.to_datetime(master_rfm_df['last_active'], utc=True, errors='coerce')
master_rfm_df['user_signup_date'] = pd.to_datetime(master_rfm_df['user_signup_date'], utc=True, errors='coerce')
master_rfm_df['rider_active_days'] = (master_rfm_df['last_active'] -  master_rfm_df['user_signup_date']).dt.days
master_rfm_df.head()








master_rfm_df.info()














collumns_needed = ['user_id','surge_exposure(%)','loyalty_status','rating_by_rider','churn_prob','recency','frequency','monetary','rider_active_days']
for col in master_rfm_df.columns:
  if col not in collumns_needed:
    master_rfm_df = master_rfm_df.drop(columns=[col])

master_rfm_df.head()


master_rfm_df.describe(include='all').transpose()


master_rfm_df[master_rfm_df['churn_prob'] >= 0.4]








master_rfm_df['monthly_trips'] = (master_rfm_df['frequency'] / master_rfm_df['rider_active_days']) * 30
master_rfm_df.head()


master_rfm_df['monthly_trips'].max()





master_rfm_df = master_rfm_df[['user_id',
                               'recency',
                               'frequency',
                               'monetary',
                               'surge_exposure(%)',
                               'loyalty_status',
                               'churn_prob',
                               'rider_active_days',
                               'rating_by_rider',
                               'monthly_trips']]
master_rfm_df.head()








def is_churning(row):

    # Condition 1:- Recency > 30 AND Churn probability > 0.5
    if row['recency'] > 30 and row['churn_prob'] > 0.5:
        return True

    # Condition 2:- Monthly trips < 1 AND Rating by rider < 4.7`
    if row['monthly_trips'] < 1 and row['rating_by_rider'] < 4.2:
        return True

    # Condition 3: Loyalty status is Gold or Platinum AND Recency > 30 AND Rating by Rider < 4.2
    if row['loyalty_status'] in ['Gold', 'Platinum'] and row['recency'] > 30 and row['rating_by_rider'] < 4.2:
        return True

    # Condition 4: Loyalty status is Gold or Platinum AND Recency > 30 AND Surge Exposure > 0.4
    if row['loyalty_status'] in ['Gold', 'Platinum'] and row['recency'] > 30 and row['surge_exposure(%)'] > 0.4:
        return False

    else:
        return False


master_rfm_df['is_churning'] = master_rfm_df.apply(is_churning, axis=1)
master_rfm_df.head()


master_rfm_df.drop(columns=['user_id'], inplace=True)   # dropping the user_id column


master_rfm_df.head(2)








loyal_map = {'Bronze':0,
             'Silver':1,
             'Gold':2,
             'Platinum':3
             }
master_rfm_df['loyalty_status'] = master_rfm_df['loyalty_status'].map(loyal_map)


master_rfm_df.head(2)





from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()


master_rfm_df['is_churning'] = le.fit_transform(master_rfm_df['is_churning'])


master_rfm_df.head(2)











columns_to_scale = ['recency', 'frequency','monetary','surge_exposure(%)','churn_prob','rider_active_days','rating_by_rider','monthly_trips']
sns.set(style='darkgrid', palette='Set2', context='paper')
fig, ax = plt.subplots(2,4, figsize=(20,7))
ax = ax.flatten()
for idx, col in enumerate(columns_to_scale):
  sns.histplot(x=master_rfm_df[col], ax=ax[idx], bins=30, kde=True, edgecolor='black')
  ax[idx].set_title(col)
plt.tight_layout()
plt.show();






columns_to_scale = ['recency', 'frequency','monetary','surge_exposure(%)','churn_prob','rider_active_days','rating_by_rider','monthly_trips']
fig, ax = plt.subplots(2,4, figsize=(20,7))
ax = ax.flatten()
for idx, col in enumerate(columns_to_scale):
  sns.boxplot(y=master_rfm_df[col], ax=ax[idx])
  ax[idx].set_title(col)
plt.tight_layout()
plt.show();











import numpy as np

# Replace infinities with NaN
master_rfm_df[columns_to_scale] = master_rfm_df[columns_to_scale].replace([np.inf, -np.inf], np.nan)

# Fill NaN with a safe value (mean, median, or 0)
master_rfm_df[columns_to_scale] = master_rfm_df[columns_to_scale].fillna(0)

# Double-check everything is finite
print(np.isfinite(master_rfm_df[columns_to_scale]).all().all())  # should return True


from sklearn.preprocessing import PowerTransformer
pt = PowerTransformer(method='yeo-johnson')


master_rfm_df[columns_to_scale] = pt.fit_transform(master_rfm_df[columns_to_scale])


master_rfm_df.head(2)


columns_to_scale = ['recency', 'frequency','monetary','surge_exposure(%)','churn_prob','rider_active_days','rating_by_rider','monthly_trips']
fig, ax = plt.subplots(2,4, figsize=(20,7))
ax = ax.flatten()
for idx, col in enumerate(columns_to_scale):
  sns.histplot(x=master_rfm_df[col], ax=ax[idx], bins=30, kde=True, edgecolor='black')
  ax[idx].set_title(col)
plt.tight_layout()
plt.show();


columns_to_scale = ['recency', 'frequency','monetary','surge_exposure(%)','churn_prob','rider_active_days','rating_by_rider','monthly_trips']
fig, ax = plt.subplots(2,4, figsize=(20,7))
ax = ax.flatten()
for idx, col in enumerate(columns_to_scale):
  sns.boxplot(y=master_rfm_df[col], ax=ax[idx])
  ax[idx].set_title(col)
plt.tight_layout()
plt.show();








from sklearn.preprocessing import StandardScaler
ss = StandardScaler()


master_rfm_df[columns_to_scale] = ss.fit_transform(master_rfm_df[columns_to_scale])


master_rfm_df.head(2)





master_rfm_df['is_churning'].value_counts(normalize=True)*100


sns.set(style='darkgrid', palette='Set2', context='paper')
plt.figure(figsize=(5,4))
sns.countplot(x='is_churning', data=master_rfm_df, palette='cubehelix')
plt.title('Target Variable Distribution', weight='bold', fontsize='12')
plt.show();


master_rfm_df.to_csv('C:/Users/User/Desktop/ridewise/data/processed_data/masters_df.csv')    # saving the dataframe








from sklearn.model_selection import train_test_split


X = master_rfm_df.drop(columns=['is_churning'])
y = master_rfm_df['is_churning']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


y_train.value_counts(normalize=True)*100    # checking the class imbalance of the target variable








from imblearn.over_sampling import SMOTE
smote = SMOTE(random_state=42)


X_resampled, y_resampled = smote.fit_resample(X_train, y_train)


y_resampled.value_counts(normalize=True)*100








from sklearn.linear_model import LogisticRegression
lg = LogisticRegression(random_state=42)


lg_model = lg.fit(X_resampled, y_resampled)
y_pred = lg_model.predict(X_test)
y_pred[:5]


y_test.head()





from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
report = classification_report(y_test, y_pred)
matrix = confusion_matrix(y_test, y_pred)
sns.heatmap(matrix, annot= True, fmt='d', cmap='Blues', xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show();
print(f'The confusion matrix of the model is: \n{matrix}')
print(f'The classification report of the model is: \n{report}')











coefficients = pd.DataFrame({'Feature':X.columns,'Coefficient': lg_model.coef_.ravel()})
coefficients_sorted = coefficients.sort_values(by='Coefficient', ascending=False)
coefficients_sorted


sns.barplot(x='Coefficient', y='Feature', data=coefficients_sorted, palette='Set2')
plt.title('Feature Importance Chart', weight='bold', fontsize='12')
plt.xlabel('Coefficient', weight='bold')
plt.ylabel('Feature', weight='bold')
plt.show();








from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB


!pip install XGBoost


from xgboost import XGBClassifier





models = {
    'RF_Classifier': RandomForestClassifier(random_state=42, class_weight='balanced'),
    'GB_Classifier': GradientBoostingClassifier(random_state=42),
    'AdaBoost_Classifier': AdaBoostClassifier(random_state=42),
    'Dt_Classifier': DecisionTreeClassifier(random_state=42, class_weight='balanced'),
    # 'SVM_Classifier': SVC(random_state=42, class_weight='balanced'),
    'KNN_Classifier': KNeighborsClassifier(),
    'NB_Classifier': GaussianNB()
    }





for model_name, model in models.items():
  print(' \n')
  print(f'Training the {model_name} model')
  model.fit(X_resampled, y_resampled)
  y_pred = model.predict(X_test)
  accuracy = accuracy_score(y_test, y_pred)
  print(f'The accuracy of the {model_name} model is: {accuracy}')
  report = classification_report(y_test, y_pred)
  matrix = confusion_matrix(y_test, y_pred)
  sns.heatmap(matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])
  plt.title(f'Confusion Matrix for {model_name}')
  plt.xlabel('Predicted')
  plt.ylabel('Actual')
  print(f'The confusion matrix of the {model_name} model is: \n{matrix}')
  print(f'The classification report of the {model_name} model is: \n{report}')
  plt.show();








from sklearn.model_selection import GridSearchCV


from sklearn.model_selection import RandomizedSearchCV

# Step 4: Define the Random Forest model
rf_model = RandomForestClassifier(random_state=42, class_weight="balanced")

# Step 5: Set up hyperparameter grid (same as before)
param_grid = {
    "n_estimators": [100, 200, 300],       # number of trees
    "max_depth": [None, 10, 20],           # depth of trees
    "min_samples_split": [2, 5, 10],       # minimum samples to split a node
    "min_samples_leaf": [1, 2, 4]          # minimum samples at a leaf
}

# Step 6: Apply RandomizedSearchCV for faster hyperparameter tuning
random_search = RandomizedSearchCV(
    estimator=rf_model,
    param_distributions=param_grid,
    n_iter=20,             # number of random combinations to try
    cv=3,                  # 3-fold cross validation
    n_jobs=-1,             # use all CPU cores
    verbose=2,
    random_state=42
)

random_search.fit(X_resampled, y_resampled)

# Step 7: Get the best model
best_rf = random_search.best_estimator_
print("âœ… Best parameters found:", random_search.best_params_)

# Step 8: Evaluate the tuned model
y_pred = best_rf.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

# Confusion Matrix
matrix = confusion_matrix(y_test, y_pred)
sns.heatmap(matrix, annot=True, fmt="d", cmap="Blues",
            xticklabels=["Predicted 0", "Predicted 1"],
            yticklabels=["Actual 0", "Actual 1"])
plt.title("Confusion Matrix for Tuned Random Forest (RandomizedSearchCV)")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show();






importances = best_rf.feature_importances_      # Getting feature importances from Random Forest

# Putting them into a DataFrame
feature_importances = pd.DataFrame({
    'Feature': X.columns,
    'Importance': importances
})

# Sort by importance
feature_importances_sorted = feature_importances.sort_values(
    by='Importance', ascending=False
)

feature_importances_sorted



sns.barplot(x='Importance', y='Feature', data=feature_importances_sorted, palette='Set2')
plt.title('Feature Importance Chart', weight='bold', fontsize='12')
plt.xlabel('Importance', weight='bold')
plt.ylabel('Feature', weight='bold')
plt.show();











from sklearn.metrics import roc_curve, roc_auc_score
y_probability = best_rf.predict_proba(X_test)[:,1]


fpr, tpr, tresholds = roc_curve(y_test, y_probability)
auc_score = roc_auc_score(y_test, y_probability)


plt.plot(fpr, tpr, label=f'AUC = {auc_score:.2f}', color='red')
plt.plot([0,1],[0,1], linestyle='--', color='black')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc='lower right')
plt.show();








import pickle

with open("C:/Users/User/Desktop/ridewise/model/random_forest_model.pkl", "wb") as f:    # Saving the best trained model as a pickle file
    pickle.dump(best_rf, f)
print("Model saved successfully as 'random_forest_model.pkl'")
with open("C:/Users/User/Desktop/ridewise/model/random_forest_model.pkl", "rb") as f:  # Load the model back for deployment or prediction
    loaded_model = pickle.load(f)
y_pred = loaded_model.predict(X_test)     # Use the loaded model to make sample predictions
print("Model loaded successfully and ready for predictions")
print("Sample predictions:", y_pred[:10])









import shap

explainer = shap.TreeExplainer(best_rf)           # Creating a SHAP explainer for the tuned Random Forest
shap_values = explainer.shap_values(X_test)       # Calculating SHAP values for the test set
shap.summary_plot(shap_values, X_test, plot_type="bar")   # Visualising feature importance (global explanation)
shap.summary_plot(shap_values, X_test)            # Detailing summary plot (shows distribution of impact per feature)
# Explaining a single prediction (local explanation)
# Pick one test sample, e.g. the first row
plt.figure(figsize=(40, 15)) # width=15, height=5 (adjust as needed)
sample_index = 0
shap.force_plot(
    explainer.expected_value[1],
    shap_values[sample_index, :, 1],
    X_test.iloc[sample_index,:],
    matplotlib=True
)




